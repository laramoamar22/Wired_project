{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bertopic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section One: Model training and Hyperparamter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.26.4 gensim==4.3.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_working_directory = os.getcwd()\n",
    "current_working_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (original text not pre-processed)\n",
    "import pandas as pd\n",
    "df = pd.read_csv('cleaned_wiredbert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df['text_content']\n",
    "docs = [doc if doc is not None and not (isinstance(doc, float) and np.isnan(doc)) else \"\" for doc in docs]\n",
    "docs = [str(doc) for doc in docs]\n",
    "non_string_elements = [doc for doc in docs if not isinstance(doc, str)]\n",
    "if non_string_elements:\n",
    "    print(\"Non-string elements found:\", non_string_elements)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly kaleido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U kaleido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run default out of the box bertopic model\n",
    "from bertopic import BERTopic\n",
    "\n",
    "defaultmodel = BERTopic()\n",
    "topics, probs = defaultmodel.fit_transform(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultmodel.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "\n",
    "# Load model vectorizer \n",
    "vectorizer = multi_topic_model.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "# Function to calculate topic coherence_npmi \n",
    "words = vectorizer.get_feature_names_out()\n",
    "tokens = [analyzer(doc) for doc in docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topic_words = []\n",
    "for topic_num in range(len(multi_topic_model.get_topics())):\n",
    "    topic = multi_topic_model.get_topic(topic_num)\n",
    "    if topic:  # Ensure the topic is not empty or invalid\n",
    "        topic_words.append([word for word, _ in topic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary, \n",
    "                                 coherence='u_mass')\n",
    "\n",
    "# Calculate the NPMI coherence score\n",
    "coherence = coherence_model.get_coherence()\n",
    "\n",
    "#print(f\"NPMI Coherence Score: {coherence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Try models with longer maximum sequence length than the default 256\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        'name': 'distilbert-base-cased  (512 tokens)',\n",
    "        'tokenizer': BertTokenizer.from_pretrained('distilbert-base-cased'),\n",
    "        'max_seq_length': 512\n",
    "    },\n",
    "    {\n",
    "        'name': 'BAAI/bge-base-en-v1.5 (512 tokens)',\n",
    "        'tokenizer': SentenceTransformer('BAAI/bge-base-en-v1.5'),\n",
    "        'max_seq_length': 512\n",
    "    },\n",
    "    {\n",
    "        'name': 'all-MiniLM-L6-v2 (256 tokens)',\n",
    "        'tokenizer': SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2'),\n",
    "        'max_seq_length': 384\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the pre-trained  defualt model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = model.tokenizer\n",
    "\n",
    "max_seq_length = tokenizer.model_max_length\n",
    "print(f\"Maximum Sequence Length: {max_seq_length}\")\n",
    "\n",
    "# Initialize lists to store results\n",
    "num_tokens_list = []\n",
    "tokens_lost_list = []\n",
    "percentage_lost_list = []\n",
    "\n",
    "# Tokenize each document with built in tokenizer and calculate percentage loss for each document \n",
    "# Loop through each document in the list\n",
    "for i, document in enumerate(docs):\n",
    "    # Tokenize the document\n",
    "    tokens = tokenizer.encode(document, truncation=False)\n",
    "\n",
    "    # Calculate the number of tokens in the document\n",
    "    num_tokens = len(tokens)\n",
    "    num_tokens_list.append(num_tokens)\n",
    "\n",
    "    # Check how many tokens are lost\n",
    "    if num_tokens > max_seq_length:\n",
    "        tokens_lost = num_tokens - max_seq_length\n",
    "        percentage_lost = (tokens_lost / num_tokens) * 100\n",
    "    else:\n",
    "        tokens_lost = 0\n",
    "        percentage_lost = 0.0\n",
    "\n",
    "    tokens_lost_list.append(tokens_lost)\n",
    "    percentage_lost_list.append(percentage_lost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot percentage loss of documents \n",
    "\n",
    "# Create a histogram of percentage loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(percentage_lost_list, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Percentage Loss Across Documents')\n",
    "plt.xlabel('Percentage Loss')\n",
    "plt.ylabel('Number of Documents')\n",
    "plt.grid(True)\n",
    "plt.savefig('percentage_loss_distribution.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try second model \n",
    "\n",
    "model2 = SentenceTransformer('BAAI/bge-base-en-v1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = model2.tokenizer\n",
    "\n",
    "max_seq_length = tokenizer.model_max_length\n",
    "print(f\"Maximum Sequence Length: {max_seq_length}\")\n",
    "\n",
    "# Initialize lists to store results\n",
    "num_tokens_list = []\n",
    "tokens_lost_list = []\n",
    "percentage_lost_list = []\n",
    "\n",
    "# Loop through each document in the list\n",
    "for i, document in enumerate(docs):\n",
    "    # Tokenize the document\n",
    "    tokens = tokenizer.encode(document, truncation=False)\n",
    "\n",
    "    # Calculate the number of tokens in the document\n",
    "    num_tokens = len(tokens)\n",
    "    num_tokens_list.append(num_tokens)\n",
    "\n",
    "    # Check how many tokens are lost\n",
    "    if num_tokens > max_seq_length:\n",
    "        tokens_lost = num_tokens - max_seq_length\n",
    "        percentage_lost = (tokens_lost / num_tokens) * 100\n",
    "    else:\n",
    "        tokens_lost = 0\n",
    "        percentage_lost = 0.0\n",
    "\n",
    "    tokens_lost_list.append(tokens_lost)\n",
    "    percentage_lost_list.append(percentage_lost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of percentage loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(percentage_lost_list, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Percentage Loss Across Documents')\n",
    "plt.xlabel('Percentage Loss')\n",
    "plt.ylabel('Number of Documents')\n",
    "plt.grid(True)\n",
    "plt.savefig('percentage_loss_distribution_baii.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer2 = model2.tokenizer\n",
    "\n",
    "# Check the maximum sequence length\n",
    "max_seq_length = tokenizer2.model_max_length\n",
    "\n",
    "print(f\"Maximum Sequence Length: {max_seq_length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third model (transformer but not sentence transformer model)\n",
    "\n",
    "model3 = SentenceTransformer('sentence-transformers/all-distilroberta-v1')\n",
    "\n",
    "\n",
    "tokenizer3 = model3.tokenizer\n",
    "\n",
    "# Check the maximum sequence length\n",
    "max_seq_length = tokenizer3.model_max_length\n",
    "\n",
    "print(f\"Maximum Sequence Length: {max_seq_length}\")\n",
    "\n",
    "\n",
    "\n",
    "num_tokens_list = []\n",
    "tokens_lost_list = []\n",
    "percentage_lost_list = []\n",
    "\n",
    "# Loop through each document in the list\n",
    "for i, document in enumerate(docs):\n",
    "    # Tokenize the document\n",
    "    tokens = tokenizer3.encode(document, truncation=False)\n",
    "\n",
    "    # Calculate the number of tokens in the document\n",
    "    num_tokens = len(tokens)\n",
    "    num_tokens_list.append(num_tokens)\n",
    "\n",
    "    # Check how many tokens are lost\n",
    "    if num_tokens > max_seq_length:\n",
    "        tokens_lost = num_tokens - max_seq_length\n",
    "        percentage_lost = (tokens_lost / num_tokens) * 100\n",
    "    else:\n",
    "        tokens_lost = 0\n",
    "        percentage_lost = 0.0\n",
    "\n",
    "    tokens_lost_list.append(tokens_lost)\n",
    "    percentage_lost_list.append(percentage_lost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(percentage_lost_list, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Percentage Loss Across Documents')\n",
    "plt.xlabel('Percentage Loss')\n",
    "plt.ylabel('Number of Documents')\n",
    "plt.grid(True)\n",
    "plt.savefig('percentage_loss_distribution_baii.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# final selection of embedding model from MTEB leaderboard \n",
    "\n",
    "embedding_model_gte = SentenceTransformer('thenlper/gte-small')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer4 = embedding_model_gte.tokenizer\n",
    "\n",
    "# Check the maximum sequence length\n",
    "max_seq_length = tokenizer4.model_max_length\n",
    "\n",
    "print(f\"Maximum Sequence Length: {max_seq_length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens_list = []\n",
    "tokens_lost_list = []\n",
    "percentage_lost_list = []\n",
    "\n",
    "# Loop through each document in the list\n",
    "for i, document in enumerate(docs):\n",
    "    # Tokenize the document\n",
    "    tokens = tokenizer4.encode(document, truncation=False)\n",
    "\n",
    "    # Calculate the number of tokens in the document\n",
    "    num_tokens = len(tokens)\n",
    "    num_tokens_list.append(num_tokens)\n",
    "\n",
    "    # Check how many tokens are lost\n",
    "    if num_tokens > max_seq_length:\n",
    "        tokens_lost = num_tokens - max_seq_length\n",
    "        percentage_lost = (tokens_lost / num_tokens) * 100\n",
    "    else:\n",
    "        tokens_lost = 0\n",
    "        percentage_lost = 0.0\n",
    "\n",
    "    tokens_lost_list.append(tokens_lost)\n",
    "    percentage_lost_list.append(percentage_lost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(percentage_lost_list, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Percentage Loss Across Documents')\n",
    "plt.xlabel('Percentage Loss')\n",
    "plt.ylabel('Number of Documents')\n",
    "plt.grid(True)\n",
    "plt.savefig('percentage_loss_distribution_baii.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-calculate embeddings as recommended by documentation best practice\n",
    "\n",
    "gte_embeddings = embedding_model_gte.encode(docs, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Pickle calculated embeddings \n",
    "\n",
    "with open('gte_embeddings.pkl', 'wb') as file:\n",
    "    pickle.dump(gte_embeddings, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load pickled embeddings for faster repeated model training \n",
    "\n",
    "with open('gte_embeddings.pkl', 'rb') as file:\n",
    "    gte_embeddings = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "# Train model with chosen embeddings but default hyperparameters as baseline \n",
    "\n",
    "topic_model_gte = BERTopic(embedding_model=embedding_model_gte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, probs = topic_model_gte.fit_transform(docs, gte_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_gte.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate coherence npmi \n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "\n",
    "vectorizer = topic_model_gte.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "\n",
    "words = vectorizer.get_feature_names_out()\n",
    "tokens = [analyzer(doc) for doc in docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topic_words = []\n",
    "for topic_num in range(len(topic_model_gte.get_topics())):\n",
    "    topic = topic_model_gte.get_topic(topic_num)\n",
    "    if topic:  # Ensure the topic is not empty or invalid\n",
    "        topic_words.append([word for word, _ in topic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary, \n",
    "                                 coherence='c_npmi')\n",
    "\n",
    "# Step 7: Calculate the NPMI coherence score\n",
    "coherence = coherence_model.get_coherence()\n",
    "\n",
    "print(f\"NPMI Coherence Score: {coherence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize hierarchical clustering \n",
    "\n",
    "topic_model_gte.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_gte = topic_model_gte.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save interactive plots as html \n",
    "\n",
    "fig_gte.write_html(\"fig_gte_intertopic.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamter tuning with Optuna with the objective of maximizing npmi coherence \n",
    "\n",
    "\n",
    "import optuna\n",
    "from bertopic import BERTopic\n",
    "from hdbscan import HDBSCAN\n",
    "import umap\n",
    "from sklearn.metrics import silhouette_score\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np\n",
    "\n",
    "def calculate_npmi_score(model, docs):\n",
    "    # Use the vectorizer from the BERTopic model to tokenize the documents\n",
    "    vectorizer = model.vectorizer_model\n",
    "    analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "    tokens = [analyzer(doc) for doc in docs]\n",
    "    \n",
    "    # Create Gensim dictionary and corpus\n",
    "    dictionary = Dictionary(tokens)\n",
    "    corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "\n",
    "    # Get the topics from BERTopic\n",
    "    topics = model.get_topics()\n",
    "    top_n_words = [[word for word, _ in topic] for topic in topics.values()]\n",
    "\n",
    "    # Compute NPMI using Gensim\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=top_n_words, \n",
    "        texts=tokens, \n",
    "        dictionary=dictionary, \n",
    "        corpus=corpus, \n",
    "        coherence='c_npmi'\n",
    "    )\n",
    "    return coherence_model.get_coherence()\n",
    "\n",
    "def objective(trial):\n",
    "    # Set hyperparameters ranges\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 15, 100)\n",
    "    min_dist = trial.suggest_float('min_dist', 0.0, 0.5)\n",
    "    min_cluster_size = trial.suggest_int('min_cluster_size', 5, 100)\n",
    "    min_samples = trial.suggest_int('min_samples', 5, 100)\n",
    "\n",
    "    # Create UMAP and HDBSCAN models with suggested parameters\n",
    "    umap_model = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, metric='cosine')\n",
    "    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples)\n",
    "\n",
    "    # Create BERTopic model with pre-calculated embeddings\n",
    "    topic_model = BERTopic(umap_model=umap_model, hdbscan_model=hdbscan_model)\n",
    "    \n",
    "    # Fit the model using the full dataset\n",
    "    topics, probs = topic_model.fit_transform(docs, embeddings=gte_embeddings)\n",
    "\n",
    "    # Calculate NPMI coherence score using the vectorizer method\n",
    "    npmi_score = calculate_npmi_score(topic_model, docs)\n",
    "    \n",
    "    return npmi_score\n",
    "\n",
    "# Create study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters: \", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save study object dataframe with all the trial information\n",
    "\n",
    "trials_df = study.trials_dataframe()\n",
    "sorted_trials_df = trials_df.sort_values(by='value', ascending=False)\n",
    "sorted_trials_df.to_csv('optuna_trials_sorted2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the hyperparameters values of the best trial \n",
    "\n",
    "from umap import UMAP\n",
    "\n",
    "umap_model = UMAP(n_neighbors=57, n_components=5, min_dist=0.023, metric='cosine', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdbscan import HDBSCAN\n",
    "\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=29, min_samples=26, metric='euclidean', cluster_selection_method='eom', prediction_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\", min_df=2, ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation import KeyBERTInspired\n",
    "keybert_model = KeyBERTInspired()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "\n",
    "ctfidf_model = ClassTfidfTransformer(bm25_weighting=True, reduce_frequent_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "topic_model = BERTopic(\n",
    "\n",
    "  # Pipeline models\n",
    "  embedding_model=embedding_model_gte,\n",
    "  umap_model=umap_model,\n",
    "  hdbscan_model=hdbscan_model,\n",
    "  ctfidf_model=ctfidf_model,\n",
    "  representation_model=keybert_model,\n",
    "\n",
    "  # Hyperparameters\n",
    "  top_n_words=10,\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(docs, gte_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info = topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load topic information for optimised model \n",
    "\n",
    "topic_info_df_optimisedgte = pd.DataFrame(topic_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info_df_optimisedgte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info_df_optimisedgte.to_csv('topic_info_optimisedgte.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create intertopic chart for optimized model \n",
    "\n",
    "gte_optimised_vis = topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gte_optimised_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gte_optimised_vis.write_html(\"intertopic_gte_optimised.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce outliers with c-tfidf method and 0.1 as probability threshold \n",
    "\n",
    "new_topics = topic_model.reduce_outliers(docs, topics , strategy=\"c-tf-idf\", threshold=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update model with reduced outliers topics \n",
    "\n",
    "topic_model.update_topics(docs, topics=new_topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducedoutlier_gte = topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info_df_reduced_gte = pd.DataFrame(reducedoutlier_gte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info_df_reduced_gte.to_csv('topic_info_reducedgte.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info_df_reduced_gte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section Two: Visualizing Optimized Model Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate topic diversity \n",
    "\n",
    "top_n_words = 10  \n",
    "topic_words = []\n",
    "for topic_num in range(len(topic_model.get_topics())):\n",
    "    topic = topic_model.get_topic(topic_num)\n",
    "    if topic:  # Ensure the topic is not empty or invalid\n",
    "        words = [word for word, _ in topic[:top_n_words]]\n",
    "        topic_words.extend(words)  # Collect all top words across all topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = set(topic_words)\n",
    "unique_word_count = len(unique_words)\n",
    "total_words = len(topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_diversity = unique_word_count / total_words\n",
    "print(f\"Topic Diversity: {topic_diversity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize hierachical clustering for optimized model \n",
    "\n",
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multi-aspect topic modelling for the different representations \n",
    "\n",
    "from bertopic.representation import PartOfSpeech\n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "\n",
    "aspect_model1 = PartOfSpeech(\"en_core_web_sm\")\n",
    "aspect_model2 = [KeyBERTInspired(top_n_words=30), MaximalMarginalRelevance(diversity=.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_model = {\n",
    "   \"Keybert\": keybert_model,\n",
    "   \"POS\":  aspect_model1,\n",
    "   \"MMR\":  aspect_model2 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_topic_model = BERTopic(\n",
    "\n",
    "  # Pipeline models\n",
    "  embedding_model=embedding_model_gte,\n",
    "  umap_model=umap_model,\n",
    "  hdbscan_model=hdbscan_model,\n",
    "  ctfidf_model=ctfidf_model,\n",
    "  representation_model=representation_model,\n",
    "\n",
    "  # Hyperparameters\n",
    "  top_n_words=10,\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "topics, probs = multi_topic_model.fit_transform(docs, gte_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topics2 = multi_topic_model.reduce_outliers(docs, topics , strategy=\"c-tf-idf\", threshold=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_topic_model.update_topics(docs, topics=new_topics2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hierarchical clustering plot with linkages \n",
    "\n",
    "from scipy.cluster import hierarchy as sch\n",
    "\n",
    "linkage_function = lambda x: sch.linkage(x, 'complete', optimal_ordering=True)\n",
    "hierarchical_topics = multi_topic_model.hierarchical_topics(docs, linkage_function=linkage_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_vis = multi_topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_vis.write_html(\"multi_hierarchy_complete.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce embeddings to 2D for clustering visualization \n",
    "\n",
    "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, \n",
    "                          min_dist=0.0, metric='cosine').fit_transform(gte_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_topic_model.visualize_documents(docs, reduced_embeddings=reduced_embeddings, \n",
    "                                hide_document_hover=True, hide_annotations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = multi_topic_model.get_topic_info()\n",
    "\n",
    "multi_df = pd.DataFrame(multi)\n",
    "\n",
    "multi_df.to_csv('topic_info_multi_gte.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bertopic transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section Three: Experimentation with NLP techniques for results interpretation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from bertopic.representation import TextGeneration\n",
    "\n",
    "# Initialize the text generation pipeline for summary label generation and enable gpu acceleration \n",
    "\n",
    "generator = pipeline('text2text-generation', model='google/flan-t5-base', device=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topic_label(topic_model, topic_id, generator):\n",
    "  \n",
    "    # Retrieve keywords for the specified topic\n",
    "    topic_keywords = topic_model.get_topic(topic_id)\n",
    "    \n",
    "    # Format the keywords as a single string\n",
    "    keywords = \", \".join([word for word, _ in topic_keywords])\n",
    "    \n",
    "    # Set the prompt\n",
    "    prompt_template = (\n",
    "    \"I have a topic described by the following keywords: [KEYWORDS]. \"\n",
    "    \"Based on these keywords, provide a two-word descriptive label that best summarizes the topic. \"\n",
    "    \"For example, if the keywords were 'AI, machine learning, deep learning', a good label might be 'AI Techniques'.\"\n",
    "    )    \n",
    "    prompt = prompt_template.replace(\"[KEYWORDS]\", keywords)\n",
    "    \n",
    "    # Generate the label\n",
    "    generated_label = generator(prompt, max_length=20, num_return_sequences=1, top_k=50, temperature=0.7)[0]['generated_text']\n",
    "    \n",
    "    # Clean up the label and ensure it is two words\n",
    "    cleaned_label = ' '.join(generated_label.strip().split()[:2])\n",
    "    \n",
    "    # Further clean-up: remove repetitve generic words\n",
    "    if cleaned_label.lower().startswith(('what', 'how', 'why')):\n",
    "        cleaned_label = cleaned_label.split(' ', 1)[-1].strip()\n",
    "\n",
    "    return cleaned_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labels_for_all_topics(topic_model, generator):\n",
    "    # Get all topic IDs from the BERTopic model\n",
    "    topic_ids = topic_model.get_topic_info()['Topic'].tolist()\n",
    "    \n",
    "    # Dictionary to store topic labels\n",
    "    topic_labels = {}\n",
    "    \n",
    "    for topic_id in topic_ids:\n",
    "        # Skip the -1 topics which represents the outliers \n",
    "        if topic_id == -1:\n",
    "            continue\n",
    "        \n",
    "        # Generate a label for each topic\n",
    "        label = generate_topic_label(topic_model, topic_id, generator)\n",
    "        topic_labels[topic_id] = label\n",
    "        print(f\"Generated label for topic {topic_id}: {label}\")\n",
    "    \n",
    "    return topic_labels\n",
    "\n",
    "topic_labels = generate_labels_for_all_topics(multi_topic_model, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the generated labels as the final column in the dataframe with the multi-representation topics \n",
    "\n",
    "topic_info_all_gte = multi_topic_model.get_topic_info()\n",
    "\n",
    "# Add the generated labels to the DataFrame\n",
    "topic_info_all_gte['Generated_Label'] = topic_info_all_gte['Topic'].map(topic_labels)\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "print(topic_info_all_gte)\n",
    "\n",
    "topic_info_all_gte.to_csv('gtemodel_all_multi.csv', index=False)\n",
    "\n",
    "print(\"DataFrame saved to 'final_model_all_multi.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_0_info = topic_info_all_gte[topic_info_all_gte['Topic'] == 0]\n",
    "\n",
    "# Extract all the representations\n",
    "topic_0_representations = topic_0_info[['Topic', 'Representation', 'Keybert', 'POS', 'MMR', 'Generated_Label']]  # Adjust columns as needed\n",
    "\n",
    "# Save the extracted information to a CSV file\n",
    "topic_0_representations.to_csv('topic_0_representations.csv', index=False)\n",
    "\n",
    "#print(\"Topic 3 representations saved to 'topic_3_representations.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(topic_0_representations.to_html(index=False)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zero shot classification pipeline with transformer model for labelling candidate labels to topics \n",
    "\n",
    "zero_shot_classifier = pipeline(\"zero-shot-classification\", model=\"valhalla/distilbart-mnli-12-1\", device=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_labels = [\"gloabl network\", \"gadgets\", \"virtual community\", \"freedom\", \"regulation\", \"cyberspace\", \"privacy\", \"international affairs\", \"silicon valley\", \"entrepreneur\", \"success\",  \n",
    "                   'innovation', 'new', 'revolution', 'progress','equal', 'communication', 'collaboration', 'risk', 'control', 'governemnt', 'hierarchy', 'protection', 'threat', 'danger']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_keywords = multi_topic_model.get_topics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify each topic to a candidate label with highest probability with a minimum threshold of 0.2 \n",
    "\n",
    "def generate_zero_shot_labels(topics_keywords, classifier, candidate_labels, threshold=0.2):\n",
    "    topic_labels = {}\n",
    "    for topic_id, keywords in topics_keywords.items():\n",
    "        if topic_id == -1:  # Skip outlier topic\n",
    "            continue\n",
    "        # Concatenate the keywords into a single string\n",
    "        keywords_str = \", \".join([word for word, _ in keywords])\n",
    "        # Use the zero-shot classifier to predict the label\n",
    "        result = classifier(keywords_str, candidate_labels)\n",
    "        # Select the label only if its score exceeds the threshold\n",
    "        if result['scores'][0] >= threshold:\n",
    "            topic_labels[topic_id] = result['labels'][0]\n",
    "        else:\n",
    "            topic_labels[topic_id] = \"Uncertain\"  \n",
    "    return topic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_labels = generate_zero_shot_labels(topics_keywords, zero_shot_classifier, candidate_labels, threshold=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info_all_gte['Zero_Shot_Label'] = topic_info_all_gte['Topic'].map(topic_labels)\n",
    "\n",
    "print(topic_info_all_gte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info_all_gte.to_csv('topic_labels_with_zero_shot_new.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "topic_info_all_gtedf = pd.read_csv('topic_labels_with_zero_shot_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = [\"global network\", \"gadgets\", \"virtual community\", \"freedom\", \"regulation\", \"cyberspace\", \"privacy\", \"international affairs\", \"silicon valley\", \"entrepreneur\", \"success\",  \n",
    "                   'innovation', 'new', 'revolution', 'progress','equal', 'communication', 'collaboration', 'risk', 'control', 'governemnt', 'hierarchy', 'protection', 'threat', 'danger']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> similar_topics, similarity = multi_topic_model.find_topics(\"control\", top_n=5)\n",
    ">>> multi_topic_model.get_topic(similar_topics[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_id = similar_topics[0]\n",
    "topic_similarity_score = similarity[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create node grpahs for keywords connected with the top 3 similar topics \n",
    "\n",
    "\n",
    "def create_and_save_keyword_topic_subgraphs(keyword_list, topic_model, output_dir, top_n=3):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for keyword in keyword_list:\n",
    "        # Create a directed graph for each keyword\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        # Add the keyword node\n",
    "        keyword_node = f\"Keyword: {keyword}\"\n",
    "        G.add_node(keyword_node)\n",
    "        \n",
    "        # Find the top_n topics for the keyword\n",
    "        similar_topics, similarity = topic_model.find_topics(keyword, top_n=top_n)\n",
    "        \n",
    "        # Add nodes and edges for the topics\n",
    "        for i, topic_id in enumerate(similar_topics):\n",
    "            topic_node = f\"Topic {topic_id}\"\n",
    "            similarity_score = similarity[i]\n",
    "            \n",
    "            # Add topic node with its similarity score\n",
    "            G.add_node(topic_node)\n",
    "            \n",
    "            # Create an edge from the keyword to the topic with the similarity score as a label\n",
    "            G.add_edge(keyword_node, topic_node, weight=similarity_score)\n",
    "        \n",
    "        # Draw the graph\n",
    "        pos = nx.spring_layout(G)\n",
    "        edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "        \n",
    "        # Draw nodes and edges with labels\n",
    "        nx.draw(G, pos, with_labels=True, node_color='lightblue', edge_color='gray', \n",
    "                node_size=3000, font_size=12, font_weight='bold', arrows=True)  # Increase font size for labels\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels={k: f\"{v:.2f}\" for k, v in edge_labels.items()}, \n",
    "                                     font_color='red', font_size=14)  # Increase font size for edge labels\n",
    "        \n",
    "        plt.title(f\"Keyword-Topic Similarity Graph for '{keyword}'\", fontsize=16)  # Increase font size for title\n",
    "        \n",
    "        plt.savefig(os.path.join(output_dir, f\"{keyword}_topic_graph.png\"))\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"keyword_topic_graphs_new\" \n",
    "create_and_save_keyword_topic_subgraphs(newlist, multi_topic_model, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_topic_representations_for_keywords(keyword_list, topic_model, top_n_topics=3, output_csv='topic_representations.csv'):\n",
    "    data = {'Keyword': [], 'Topic ID': [], 'Topic Representation': []}\n",
    "    \n",
    "    for keyword in keyword_list:\n",
    "        # Find the top_n_topics for the keyword\n",
    "        similar_topics, similarity_scores = topic_model.find_topics(keyword, top_n=top_n_topics)\n",
    "        \n",
    "        for i, topic_id in enumerate(similar_topics):\n",
    "            # Get the topic representation\n",
    "            topic_representation = topic_model.get_topic(topic_id)\n",
    "            # Convert the topic representation to a string format\n",
    "            topic_representation_str = ', '.join([word for word, _ in topic_representation])\n",
    "            \n",
    "            # Add the keyword, topic ID, and topic representation to the DataFrame\n",
    "            data['Keyword'].append(keyword)\n",
    "            data['Topic ID'].append(topic_id)\n",
    "            data['Topic Representation'].append(topic_representation_str)\n",
    "    \n",
    "    result_df = pd.DataFrame(data)\n",
    "    result_df.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv = \"topic_representations.csv\"  # Output CSV file path\n",
    "save_topic_representations_for_keywords(newlist, multi_topic_model, top_n_topics=3, output_csv=output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representative_docs_and_titles_for_topics(topic_ids, topic_model, df, top_n=3):\n",
    "    \n",
    "    # List to hold the output data\n",
    "    output_data = []\n",
    "\n",
    "    for topic_id in topic_ids:\n",
    "        # Get the representative documents for the given topic\n",
    "        representative_docs = topic_model.get_representative_docs(topic_id)[:top_n]\n",
    "        \n",
    "        for doc in representative_docs:\n",
    "            # Find the corresponding title for each representative document\n",
    "            title = df.loc[df['text_content'] == doc, 'title'].values[0]\n",
    "            # Append the topic ID, title, and document text to the output data\n",
    "            output_data.append({\n",
    "                'topic_id': topic_id,\n",
    "                'title': title,\n",
    "                'document_text': doc\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = get_representative_docs_and_titles_for_topics(china, multi_topic_model, df, top_n=3)\n",
    "\n",
    "output_df.to_csv(f\"representative_docs_for_topic_{china}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "topic_assignments = multi_topic_model.topics_  # Get the topic assignment for each document\n",
    "\n",
    "\n",
    "# Count the number of documents assigned to each topic\n",
    "topic_counts = Counter(topic_assignments)\n",
    "\n",
    "# Get the number of documents for each selected topic\n",
    "selected_topic_counts = {topic: topic_counts.get(topic, 0) for topic in china}\n",
    "\n",
    "# Calculate the total number of documents assigned to the selected topics\n",
    "total_documents = sum(selected_topic_counts.values())\n",
    "\n",
    "print(\"Document counts per selected topic:\")\n",
    "for topic, count in selected_topic_counts.items():\n",
    "    print(f\"Topic {topic}: {count} documents\")\n",
    "\n",
    "print(f\"\\nTotal number of documents in selected topics: {total_documents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add edges based on co-occurrence of keywords and entities\n",
    "for idx, row in df.iterrows():\n",
    "    keywords = row['technoutopian_keywords']\n",
    "    entities = [ent[0] for ent in row['entities']]\n",
    "    for keyword in keywords:\n",
    "        for entity in entities:\n",
    "            G.add_edge(keyword, entity)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw_networkx(G, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_df['document_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy matplotlib scikit-learn pandas datashader scikit-image numba requests jinja2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_representations = multi_topic_model.get_topic_info()\n",
    "\n",
    "topic_ids = topic_representations['Topic'].values\n",
    "topic_names = topic_representations['Name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [f\"Topic {topic_id}: {topic_repr}\" for topic_id, topic_repr in zip(topic_ids, topic_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_per_doc = multi_topic_model.get_document_info(docs)[\"Topic\"].values\n",
    "named_topic_per_doc = [labels[topic_id] for topic_id in topic_per_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = datamapplot.create_plot(\n",
    "    reduced_embeddings,\n",
    "    named_topic_per_doc,\n",
    "    figsize=(10, 8),\n",
    "    title=\"Topic Map\",\n",
    "    sub_title=\"Visualization of Topics with IDs and Representations\"\n",
    ")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final topic lists for defined theme categories\n",
    "\n",
    "china =[121,66,110]\n",
    "culture = [51, 129, 24, 107, 29, 19, 83, 71, 90, 34, 53]\n",
    "Silicon_valley = [92,80, 64]\n",
    "Online_activity = [11, 61, 11, 8, 4, 103, 1, 9, 97, 63, 38, 33, 22, 69]\n",
    "cybersecurity = [32, 5, 16, 15, 14, 6, 13, 10, 53, 42, 88, 39, 119, 105, 95]\n",
    "techcompanies = [127, 130, 37, 3, 124, 27, 46, 118]\n",
    "stock = [100, 94, 23, 25, 114, 28, 12, 0, 101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get document information\n",
    "document_info = multi_topic_model.get_document_info(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_topic_model.visualize_barchart(topics=[121, 66, 110])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_topic_ids = list(topic_aspects.keys())\n",
    "print(\"Available topic IDs:\", available_topic_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select the representation type and topic ID\n",
    "representation_type = 'POS'\n",
    "topic_id = 121 \n",
    "\n",
    "# Extract the representation terms and scores\n",
    "try:\n",
    "    representation = topic_aspects[representation_type][topic_id]\n",
    "    \n",
    "    terms, scores = zip(*representation)  # Unzip terms and scores\n",
    "\n",
    "    # Manually plot the term bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(terms[::-1], scores[::-1], color='skyblue')  # Reverse to plot highest score at the top\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Terms')\n",
    "    plt.title(f'Term Chart for Topic {topic_id} ({representation_type} Representation)')\n",
    "    plt.show()\n",
    "\n",
    "except KeyError:\n",
    "    print(f\"Topic {topic_id} not found in the '{representation_type}' representation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(24, 8)) \n",
    "topic_aspects = multi_topic_model.topic_aspects_\n",
    "\n",
    "representation_type = 'POS'\n",
    "# Font settings\n",
    "font_size_title = 16\n",
    "font_size_labels = 14\n",
    "font_size_ticks = 12\n",
    "\n",
    "# Loop over each topic and create a subplot\n",
    "for ax, topic_id in zip(axes, techcompanies):\n",
    "    try:\n",
    "        representation = topic_aspects[representation_type][topic_id]\n",
    "        terms, scores = zip(*representation)  # Unzip terms and scores\n",
    "\n",
    "        # Plot the term bar chart in the current subplot\n",
    "        ax.barh(terms[::-1], scores[::-1], color='skyblue')\n",
    "        ax.set_xlabel('Importance', fontsize=font_size_labels)\n",
    "        ax.set_ylabel('Terms', fontsize=font_size_labels)\n",
    "        ax.set_title(f'Topic {topic_id} ({representation_type})', fontsize=font_size_title)\n",
    "        \n",
    "        # Set tick parameters\n",
    "        ax.tick_params(axis='both', which='major', labelsize=font_size_ticks)\n",
    "\n",
    "    except KeyError:\n",
    "        ax.set_title(f'Topic {topic_id} not found', fontsize=font_size_title)\n",
    "        ax.axis('off')  # Hide the axis if the topic is not found\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'term_charts_topics_{techcompanies[0]}_{techcompanies[1]}_{techcompanies[2]}_{representation_type}.png', format='png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_types = ['Keybert', 'POS', 'MMR']\n",
    "\n",
    "for topic in selected_topics:\n",
    "    for rep_type in representation_types:\n",
    "        try:\n",
    "            representation = topic_aspects[rep_type][topic]\n",
    "            print(f\"Topic {topic} ({rep_type}) Representation: {representation}\")\n",
    "        except KeyError:\n",
    "            print(f\"Topic {topic} not found in the '{rep_type}' representation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "num_topics = len(culture)\n",
    "cols = 3  \n",
    "rows = math.ceil(num_topics / cols) d\n",
    "\n",
    "for ax, topic_id in zip(axes, culture):\n",
    "    try:\n",
    "        representation = topic_aspects[representation_type][topic_id]\n",
    "        if not representation:\n",
    "            raise ValueError(\"Empty representation data\")\n",
    "\n",
    "        terms, scores = zip(*representation)  # Unzip terms and scores\n",
    "\n",
    "        print(f\"Topic {topic_id} terms: {terms}\")\n",
    "        print(f\"Topic {topic_id} scores: {scores}\")\n",
    "\n",
    "        # Plot the term bar chart in the current subplot\n",
    "        ax.barh(terms[::-1], scores[::-1], color='skyblue')\n",
    "        ax.set_xlabel('Importance')\n",
    "        ax.set_ylabel('Terms')\n",
    "        ax.set_title(f'Topic {topic_id} ({representation_type})')\n",
    "\n",
    "    except KeyError:\n",
    "        ax.set_title(f'Topic {topic_id} not found')\n",
    "        ax.axis('off')  # Hide the axis if the topic is not found\n",
    "    except ValueError as ve:\n",
    "        print(f\"ValueError: {ve}\")\n",
    "        ax.set_title(f'Topic {topic_id} Error')\n",
    "        ax.axis('off')\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        ax.set_title(f'Topic {topic_id} Error')\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_documents_by_topic_ids(topic_ids, document_info, docs):\n",
    "    \n",
    "    topic_docs = {}  # Initialize an empty dictionary\n",
    "    \n",
    "    # Verify that docs and document_info are valid\n",
    "    if not docs:\n",
    "        raise ValueError(\"The 'docs' list is empty.\")\n",
    "    \n",
    "    if 'Topic' not in document_info:\n",
    "        raise ValueError(\"'Topic' key not found in document_info.\")\n",
    "    \n",
    "    if len(document_info['Topic']) != len(docs):\n",
    "        raise ValueError(\"Length mismatch between 'document_info' and 'docs'.\")\n",
    "    \n",
    "    for topic_id in topic_ids:\n",
    "        # Reinitialize doc_indices for each topic_id\n",
    "        doc_indices = [i for i, topic in enumerate(document_info['Topic']) if topic == topic_id]\n",
    "        doc_indices = [i for i in doc_indices if i < len(docs)]\n",
    "        \n",
    "        # Extract the documents using the valid indices\n",
    "        selected_docs = [docs[i] for i in doc_indices]\n",
    "        topic_docs[topic_id] = selected_docs\n",
    "    \n",
    "    return topic_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_docs = extract_documents_by_topic_ids(china, document_info, docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_id, documents in extracted_docs.items():\n",
    "    print(f\"Topic {topic_id}: {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_id, documents in extracted_docs.items():\n",
    "    print(f\"Processing Topic ID: {topic_id}\")\n",
    "    \n",
    "    # Combine all documents for this topic into a single text\n",
    "    combined_text = ' '.join(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_ngram_analysis(text, ngram_range=(2, 2), top_n=20):\n",
    "    \n",
    "    # Initialize CountVectorizer to extract n-grams\n",
    "    vectorizer = CountVectorizer(ngram_range=ngram_range, stop_words='english')\n",
    "\n",
    "    # Fit and transform the text data to get n-grams\n",
    "    ngrams = vectorizer.fit_transform([text])\n",
    "    \n",
    "    # Get the frequency of each n-gram\n",
    "    ngram_freq = ngrams.toarray().flatten()  # Convert sparse matrix to a dense array and flatten to 1D\n",
    "    \n",
    "    ngram_freq_df = pd.DataFrame({'frequency': ngram_freq}, index=vectorizer.get_feature_names_out())\n",
    "    \n",
    "    # Sort n-grams by frequency\n",
    "    ngram_freq_df = ngram_freq_df.sort_values(by='frequency', ascending=False)\n",
    "    \n",
    "    # Return the top N n-grams\n",
    "    return ngram_freq_df.head(top_n)\n",
    "\n",
    "all_ngram_results = pd.DataFrame()\n",
    "\n",
    "\n",
    "for topic_id, documents in extracted_docs.items():\n",
    "    print(f\"\\nAnalyzing Topic ID: {topic_id}\")\n",
    "  \n",
    "    combined_text = ' '.join(documents)\n",
    "    \n",
    "    ngram_results = perform_ngram_analysis(combined_text, ngram_range=(2, 2), top_n=20)  # Change ngram_range as needed\n",
    "  \n",
    "    ngram_results['Topic_ID'] = topic_id\n",
    "    \n",
    "    all_ngram_results = pd.concat([all_ngram_results, ngram_results])\n",
    "\n",
    "all_ngram_results.to_csv('bigram_analysis_results.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ngram_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load Spacy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load phrasematcher to match phrases with ner entities \n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ner(documents):\n",
    "    \n",
    "    ner_results = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        spacy_doc = nlp(doc)\n",
    "        entities = [(ent.text, ent.label_) for ent in spacy_doc.ents]\n",
    "        ner_results.append(entities)\n",
    "    \n",
    "    return ner_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_topic_ids_and_apply_ner(topic_ids, document_info, docs):\n",
    "   \n",
    "    # Extract documents for selected topic category list \n",
    "    extracted_docs = extract_documents_by_topic_ids(Silicon_valley, document_info, docs)\n",
    "    \n",
    "    # Apply NER to the extracted documents\n",
    "    topic_entities = {}\n",
    "    for topic_id, documents in extracted_docs.items():\n",
    "        topic_entities[topic_id] = apply_ner(documents)\n",
    "    \n",
    "    return topic_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_context_sentences_for_ner(ner_results, term):\n",
    "    term_sentences = {}\n",
    "    \n",
    "    # Initialize PhraseMatcher\n",
    "    phrase_matcher = PhraseMatcher(nlp.vocab)\n",
    "    patterns = [nlp(term)]\n",
    "    phrase_matcher.add('TERM', None, *patterns)\n",
    "    \n",
    "    for topic_id, entities_list in ner_results.items():\n",
    "        # Extract documents for the topic\n",
    "        docs_for_topic = extract_documents_by_topic_ids([topic_id], document_info, docs)[topic_id]\n",
    "        context_sentences = []\n",
    "        \n",
    "        for doc in docs_for_topic:\n",
    "            spacy_doc = nlp(doc)\n",
    "            for sent in spacy_doc.sents:\n",
    "                for match_id, start, end in phrase_matcher(nlp(sent.text)):\n",
    "                    if nlp.vocab.strings[match_id] == 'TERM':\n",
    "                        context_sentences.append(sent.text)\n",
    "        \n",
    "        term_sentences[topic_id] = context_sentences\n",
    "    \n",
    "    return term_sentences\n",
    "\n",
    "term = \"India\" # Select NER term \n",
    "selected_topic_ids = Silicon_valley  \n",
    "\n",
    "# Apply NER and extract context sentences for the given term\n",
    "entities = process_topic_ids_and_apply_ner(selected_topic_ids, document_info, docs)\n",
    "context_sentences = find_context_sentences_for_ner(entities, term)\n",
    "\n",
    "for topic_id, sentences in context_sentences.items():\n",
    "    print(f\"Topic ID {topic_id}:\")\n",
    "    # Limit to top 10 sentences\n",
    "    for sentence in sentences[:10]:\n",
    "        print(f\"  {sentence}\")\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_entities = process_topic_ids_and_apply_ner(stock, document_info, docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_topic_model.get_document_info(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ner_to_csv(ner_results, filename):\n",
    "    rows = []\n",
    "    for topic_id, documents in ner_results.items():\n",
    "        for i, doc_entities in enumerate(documents):\n",
    "            for entity, label in doc_entities:\n",
    "                rows.append({\n",
    "                    'Topic ID': topic_id,\n",
    "                    'Document Index': i,\n",
    "                    'Entity': entity,\n",
    "                    'Label': label\n",
    "                })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ner_to_csv(entities, 'stock_ner_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('china_topic_entities.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Topic_ID', 'Entity', 'Label'])\n",
    "    for topic_id, entities in topic_entities.items():\n",
    "        for entity, label in entities:\n",
    "            writer.writerow([topic_id, entity, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_id = 121 \n",
    "select_docs = multi_topic_model.get_representative_docs(topic_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if select_docs:\n",
    "    first_document = select_docs[0]\n",
    "    print(\"First document for topic ID\", topic_id, \":\", first_document)\n",
    "else:\n",
    "    print(\"No documents found for topic ID\", topic_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter ner results by selected entity \n",
    "\n",
    "filename = 'Silicon_valley_ner_results.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# Filter rows for selected label such as GPE or ORG\n",
    "org_df = df[df['Label'] == 'GPE']\n",
    "\n",
    "# Count the occurrences of each organization entity\n",
    "org_counts = org_df['Entity'].value_counts()\n",
    "\n",
    "# Get the top 5 most frequent entities\n",
    "top_10_orgs = org_counts.nlargest(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot frequency count for top 10 selected entity \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_10_orgs.plot(kind='bar', color='skyblue')\n",
    "plt.xlabel('Organization')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Top 10 Organization Entities')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig('top_10_people.png', format='png', dpi=300) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "# Plot and save similarity matrix heatmap for topic categories \n",
    "\n",
    "# further analysis for first major category online active \n",
    "Online_activity = [11, 61, 11, 8, 4, 103, 1, 9, 97, 63, 38, 33, 22, 69]\n",
    "\n",
    "\n",
    "\n",
    "heatmap_fig = multi_topic_model.visualize_heatmap(topics=Silicon_valley)\n",
    "\n",
    "#heatmap_fig.write_html('cyber_heatmap_visualization.html', auto_open=True)\n",
    "\n",
    "heatmap_fig.update_coloraxes(colorbar_x=1.1)  # Moves the color bar further right\n",
    "\n",
    "heatmap_fig.update_layout(width=900, height=800)\n",
    "\n",
    "heatmap_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_topic_model.visualize_barchart(topics=techcompanies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_type = 'POS' \n",
    "Online_activity = [11, 61, 8, 4, 103, 1, 9, 97, 63, 38, 33, 22, 69]\n",
    "topic_aspects = multi_topic_model.topic_aspects_\n",
    "\n",
    "data = []\n",
    "\n",
    "# Extract the topic representations for the selected topic categories and convert to DataFrame\n",
    "for topic_id in culture:\n",
    "    try:\n",
    "        # Access the specific representation for the topic\n",
    "        representation = topic_aspects[representation_type][topic_id]\n",
    "        \n",
    "        # Extract terms and their scores as a list of tuples\n",
    "        terms_scores = [(term, score) for term, score in representation]\n",
    "\n",
    "        \n",
    "        # Append the data as a dictionary with Topic ID and the combined terms-scores\n",
    "        data.append({\n",
    "            'Topic ID': topic_id,\n",
    "            'Terms': [term for term, score in terms_scores],  # List of terms\n",
    "            'Scores': [score for term, score in terms_scores]  # List of scores\n",
    "        })\n",
    "    except KeyError:\n",
    "        print(f\"Topic ID {topic_id} or representation type {representation_type} not found.\")\n",
    "\n",
    "culturedf = pd.DataFrame(data)\n",
    "print(culturedf)\n",
    "\n",
    "culturedf.to_csv('culture_representations_POS.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info_df = multi_topic_model.get_topic_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter topic information by selected representation \n",
    "\n",
    "filtered_df = topic_info_df[topic_info_df['Topic'].isin(china)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmr_terms = filtered_df[['Topic', 'MMR']]\n",
    "pos_terms = filtered_df[['Topic', 'POS']]\n",
    "keybert_terms = filtered_df[['Topic', 'Keybert']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_terms = {}\n",
    "\n",
    "for _, row in filtered_df.iterrows():\n",
    "    topic_id = row['Topic']\n",
    "    mmr_terms = row['MMR']\n",
    "    pos_terms = row['POS']\n",
    "    keybert_terms = row['Keybert']\n",
    "    \n",
    "    # Combine terms and convert to a set to get unique terms\n",
    "    all_terms = set(mmr_terms + pos_terms + keybert_terms)\n",
    "    combined_terms[topic_id] = list(all_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_terms_df = pd.DataFrame(list(combined_terms.items()), columns=['Topic', 'Combined_Terms'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largedf = pd.DataFrame({\"Document\": df['text_content'], \"Topic\": topics, \"Year\": df['year']})\n",
    "\n",
    "largedf['Year'] = largedf['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert topics over time using Years column from original dataframe\n",
    "\n",
    "topics_over_time = multi_topic_model.topics_over_time(\n",
    "    docs=largedf['Document'].tolist(),  # List of documents\n",
    "    timestamps=largedf['Year'].tolist()  # Corresponding years\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_time = multi_topic_model.visualize_topics_over_time(topics_over_time, topics= techcompanies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> similar_topics, similarity = multi_topic_model.find_topics(\"outsource\", top_n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> multi_topic_model.get_topic(similar_topics[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_ids = similar_topics  # Extracting topic IDs\n",
    "\n",
    "# Print the topic IDs\n",
    "print(topic_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct sentiment analysis using FinBERT model for documents under the financial stock market category\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load FinBERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "model = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone')\n",
    "\n",
    "# Create a pipeline for sentiment analysis\n",
    "sentiment_analysis = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_info = multi_topic_model.get_document_info(docs)\n",
    "\n",
    "# Filter documents based on topic IDs\n",
    "filtered_documents = document_info[document_info['Topic'].isin(stock)]\n",
    "\n",
    "# Extract the texts of the filtered documents\n",
    "texts_to_analyze = filtered_documents['Document'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "def truncate_texts(texts, tokenizer, max_length=512):\n",
    "    truncated_texts = []\n",
    "    for text in texts:\n",
    "        # Tokenize the text\n",
    "        tokens = tokenizer.encode(text, truncation=True, max_length=max_length)\n",
    "        # Decode tokens back to string\n",
    "        truncated_text = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "        truncated_texts.append(truncated_text)\n",
    "    return truncated_texts\n",
    "\n",
    "# Truncate texts to avoid exceeding max token length\n",
    "texts_to_analyze_truncated = truncate_texts(texts_to_analyze, sentiment_analysis.tokenizer)\n",
    "\n",
    "# Run sentiment analysis on truncated texts\n",
    "sentiment_results = sentiment_analysis(texts_to_analyze_truncated)\n",
    "print(\"Raw sentiment results:\")\n",
    "\n",
    "for result in sentiment_results:\n",
    "    print(result)\n",
    "\n",
    "filtered_documents = pd.DataFrame({\n",
    "    'Document': texts_to_analyze_truncated\n",
    "})\n",
    "\n",
    "\n",
    "# Extract sentiment results\n",
    "sentiments = []\n",
    "positive_scores = []\n",
    "negative_scores = []\n",
    "neutral_scores = []\n",
    "\n",
    "for result in sentiment_results:\n",
    "    # Initialize scores\n",
    "    pos_score = neg_score = neu_score = 0.0\n",
    "    \n",
    "    # Check if result is a list of dictionaries\n",
    "    if isinstance(result, list):\n",
    "        for label_score in result:\n",
    "            if isinstance(label_score, dict):\n",
    "                label = label_score['label']\n",
    "                score = label_score['score']\n",
    "                \n",
    "                if label == 'POSITIVE':\n",
    "                    pos_score = score\n",
    "                elif label == 'NEGATIVE':\n",
    "                    neg_score = score\n",
    "                elif label == 'NEUTRAL':\n",
    "                    neu_score = score\n",
    "    \n",
    "    # Determine the overall sentiment\n",
    "    sentiments.append('POSITIVE' if pos_score > max(neg_score, neu_score) else\n",
    "                       'NEGATIVE' if neg_score > max(pos_score, neu_score) else\n",
    "                       'NEUTRAL')\n",
    "    positive_scores.append(pos_score)\n",
    "    negative_scores.append(neg_score)\n",
    "    neutral_scores.append(neu_score)\n",
    "\n",
    "# Add sentiment results to the DataFrame\n",
    "filtered_documents['Sentiment'] = sentiments\n",
    "filtered_documents['Positive Score'] = positive_scores\n",
    "filtered_documents['Negative Score'] = negative_scores\n",
    "filtered_documents['Neutral Score'] = neutral_scores\n",
    "\n",
    "output_csv_path = 'filtered_documents_with_sentiment_scores.csv'\n",
    "\n",
    "filtered_documents[['Document', 'Sentiment', 'Positive Score', 'Negative Score', 'Neutral Score']].to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Data saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sentiment_results) != len(filtered_documents):\n",
    "    raise ValueError(\"The number of sentiment results does not match the number of documents.\")\n",
    "\n",
    "# Create DataFrame for sentiment results\n",
    "sentiment_df = pd.DataFrame(sentiment_results)\n",
    "\n",
    "# Add document column for merging \n",
    "sentiment_df['Document'] = filtered_documents['Document']\n",
    "\n",
    "# Merge the two dataframes\n",
    "merged_df = pd.merge(filtered_documents, sentiment_df, on='Document', how='left')\n",
    "\n",
    "\n",
    "merged_df = merged_df.rename(columns={\n",
    "    'label': 'Sentiment Label',\n",
    "    'score': 'Sentiment Score'\n",
    "})\n",
    "\n",
    "# Add Positive, Negative, and Neutral Score columns\n",
    "merged_df['Positive Score'] = merged_df.apply(lambda row: row['Sentiment Score'] if row['Sentiment Label'] == 'Positive' else 0.0, axis=1)\n",
    "merged_df['Negative Score'] = merged_df.apply(lambda row: row['Sentiment Score'] if row['Sentiment Label'] == 'Negative' else 0.0, axis=1)\n",
    "merged_df['Neutral Score'] = merged_df.apply(lambda row: row['Sentiment Score'] if row['Sentiment Label'] == 'Neutral' else 0.0, axis=1)\n",
    "\n",
    "print(merged_df[['Document', 'Sentiment Label', 'Sentiment Score', 'Positive Score', 'Negative Score', 'Neutral Score']])\n",
    "output_csv_path = 'filtered_documents_with_sentiment_scores.csv'\n",
    "merged_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Data saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Count occurrences of each sentiment label\n",
    "sentiment_counts = merged_df['Sentiment Label'].value_counts()\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette='viridis')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Sentiment Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Sentiment Labels')\n",
    "plt.xticks(rotation=45)  # Rotate labels for better readability\n",
    "output_img_path = 'sentiment_distribution.png'\n",
    "plt.savefig(output_img_path)\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_positive_docs = merged_df.sort_values(by='Positive Score', ascending=False).head(10)\n",
    "\n",
    "# Get top 10 documents with highest negative scores\n",
    "top_negative_docs = merged_df.sort_values(by='Negative Score', ascending=False).head(10)\n",
    "\n",
    "# Print the results\n",
    "print(\"Top 10 Documents with Highest Positive Scores:\")\n",
    "print(top_positive_docs[['Document', 'Positive Score']])\n",
    "\n",
    "print(\"\\nTop 10 Documents with Highest Negative Scores:\")\n",
    "print(top_negative_docs[['Document', 'Negative Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts = filtered_documents['Sentiment'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Sentiment Counts:\")\n",
    "print(sentiment_counts)\n",
    "print(filtered_documents[['Topic', 'Document', 'Sentiment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_to_category = {}\n",
    "\n",
    "# Function to add topics to the mapping\n",
    "def add_to_mapping(topics, category_name):\n",
    "    for topic_id in topics:\n",
    "        topic_to_category[topic_id] = category_name\n",
    "\n",
    "# Add each category and its topics to the mapping\n",
    "add_to_mapping(china, 'China')\n",
    "add_to_mapping(culture, 'Culture')\n",
    "add_to_mapping(Silicon_valley, 'Silicon Valley')\n",
    "add_to_mapping(Online_activity , 'Online Activity')\n",
    "add_to_mapping(cybersecurity, 'Cybersecurity')\n",
    "add_to_mapping(techcompanies, 'Tech Companies')\n",
    "add_to_mapping(stock, 'Stock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topic_to_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_info = multi_topic_model.get_document_info(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_info['Category'] = document_info['Topic'].map(topic_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_info['Category'].fillna('Unlabeled', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = pd.DataFrame({\n",
    "    'x': reduced_embeddings[:, 0],   \n",
    "    'y': reduced_embeddings[:, 1],   \n",
    "    'Category': document_info['Category']  # Category labels for each document\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2D UMAP embedding visulization\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_plot, x='x', y='y',\n",
    "    color='Category',                \n",
    "    color_discrete_map={  \n",
    "        'China': 'red',\n",
    "        'Culture': 'blue',\n",
    "        'Silicon Valley': 'green',\n",
    "        'Online Activity': 'purple',\n",
    "        'Cybersecurity': 'orange',\n",
    "        'Tech Companies': 'cyan',\n",
    "        'Stock': 'magenta',\n",
    "        'Unlabeled': 'gray'  # Color for unlabeled points\n",
    "    },\n",
    "    title=\"UMAP Visualization of Documents by Category\",\n",
    "    template=\"plotly_dark\",  # Use a dark background\n",
    "    width=1000,              # Set width\n",
    "    height=1200               # Set height\n",
    ")\n",
    "\n",
    "# Save the interactive plot as an HTML file\n",
    "fig.write_html(\"umap_visualization.html\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary statistics plot for topic categories \n",
    "\n",
    "category_counts = pd.Series(topic_to_category.values()).value_counts().sort_index()\n",
    "\n",
    "# Create a DataFrame for Plotly\n",
    "df_plot = pd.DataFrame({\n",
    "    'Category': category_counts.index,\n",
    "    'Count': category_counts.values\n",
    "})\n",
    "\n",
    " # Create a horizontal bar chart using Plotly\n",
    "fig = px.bar(\n",
    "    df_plot, x='Count', y='Category',\n",
    "    orientation='h',  # Horizontal bar chart\n",
    "    title=\"Number of Topics in Each Category\",\n",
    "    labels={'Count': 'Number of Topics', 'Category': 'Category'},\n",
    "    template=\"plotly_white\"  # Light theme for better visibility\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(title='Number of Topics', title_font=dict(size=18)),\n",
    "    yaxis=dict(title='Category', title_font=dict(size=18)),\n",
    "    margin=dict(l=100, r=50, t=50, b=50),  # Adjust margins for better space usage\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Save the plot as an HTML file\n",
    "fig.write_html(\"topics_per_category_bar_chart.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
